{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNP-Paribas Classification Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import numpy as np\n",
    "import os, csv, json\n",
    "\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# pretty charting\n",
    "import seaborn as sns\n",
    "sns.set_palette('muted')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114321, 133)\n"
     ]
    }
   ],
   "source": [
    "#### RUN AT BEGINNING AND TRY NOT TO RUN AGAIN - TAKES WAY TOO LONG ####\n",
    "# load in test set to get labels\n",
    "column = {}\n",
    "targets = [] #np.array((), dtype=np.dtype('float64'))\n",
    "with open('train.csv', 'rb') as file:\n",
    "    reader = csv.reader(file)\n",
    "    headers = reader.next()\n",
    "    \n",
    "    # get headers\n",
    "    for h in headers:\n",
    "        column[h] = []\n",
    "    \n",
    "    # append data\n",
    "    for row in reader:\n",
    "        # just create a matrix of all features\n",
    "        targets.append(row)\n",
    "        \n",
    "        for h, v in zip(headers, row):\n",
    "            # create a dict to access specific columns\n",
    "            column[h].append(v)\n",
    "            \n",
    "# conver to a numpy matrix\n",
    "targets = np.array(targets)\n",
    "\n",
    "print targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228714, 131)\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "#### RUN AT BEGINNING AND TRY NOT TO RUN AGAIN - TAKES WAY TOO LONG ####\n",
    "# load in the feature data\n",
    "column = {}\n",
    "list_of_features = [] #np.array((), dtype=np.dtype('float64'))\n",
    "with open('imputedData.csv', 'rb') as file:\n",
    "    reader = csv.reader(file)\n",
    "    headers = reader.next()\n",
    "    \n",
    "    # get headers\n",
    "    for h in headers:\n",
    "        column[h] = []\n",
    "    \n",
    "    # append data\n",
    "    for row in reader:\n",
    "        # just create a matrix of all features\n",
    "        list_of_features.append(row)\n",
    "        \n",
    "        for h, v in zip(headers, row):\n",
    "            # create a dict to access specific columns\n",
    "            column[h].append(v)\n",
    "            \n",
    "# conver to a numpy matrix\n",
    "list_of_features = np.array(list_of_features)\n",
    "\n",
    "print list_of_features.shape\n",
    "print len(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114321\n",
      "(114321,)\n",
      "(114321, 131)\n"
     ]
    }
   ],
   "source": [
    "# create vector for targets - binary classification\n",
    "targets = column['target'] \n",
    "features = list_of_features[0:len(targets), :]\n",
    "\n",
    "targets = np.array(targets)\n",
    "features = np.array(features)\n",
    "\n",
    "print targets.shape\n",
    "print features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345678)  # for reproducibility, set random seed\n",
    "\n",
    "# define number of subjects per class\n",
    "S = np.array((8, 16, 20, 32, 40, 64, 80, 100, 120, 200, 320,\n",
    "              400, 800, 1000))\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"Random Forest\",\n",
    "         \"Linear Discriminant Analysis\", \"Quadratic Discriminant Analysis\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy=np.zeros((len(classifiers),2))\n",
    "for idx, cla in enumerate(classifiers):\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(features, targets, test_size=0.4, random_state=0)\n",
    "    clf = cla.fit(X_train, y_train)\n",
    "    loo = LeaveOneOut(len(features))\n",
    "    \n",
    "    scores = cross_validation.cross_val_score(clf, features, targets, cv=loo)\n",
    "    accuracy[idx,] = [scores.mean(), scores.std()]\n",
    "    print(\"Accuracy of %s: %0.2f (+/- %0.2f)\" % (names[idx], scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion:\n",
    "We need to downsample in order to run this analysis. There are way too many features and since the test size is so big, we need to downsample the features at least.\n",
    "\n",
    "-> Plot correlation matrix and get the ones that aren't correlated and try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
