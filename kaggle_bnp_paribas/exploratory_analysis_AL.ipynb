{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BNP-Paribas Kaggle Challenge \n",
    "Adam Li, adam2392\n",
    "\n",
    "Submission of the data should be 2 columns:\n",
    "'id' and 'predictedprob'.\n",
    "\n",
    "\n",
    "https://www.kaggle.com/c/bnp-paribas-cardif-claims-management/details/evaluation\n",
    "\n",
    "Evaluation:\n",
    "The evaluation metric for this competition is Log Loss\n",
    "\n",
    "$$logloss = −1/N \\sum_{i=1}^{N} (y_i*log(p_i) + (1−y_i)*log(1−p_i))$$\n",
    "\n",
    "where \n",
    "* N is the number of observations, \n",
    "* loglog is the natural logarithm, \n",
    "* yiyi is the binary target, and \n",
    "* pipi is the predicted probability that yiyi equals 1.\n",
    "\n",
    "Note: the actual submitted predicted probabilities are replaced with max(min(p,1−10−15),10−15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import numpy as np\n",
    "import os, csv, json\n",
    "\n",
    "from matplotlib import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "import skimage.measure\n",
    "\n",
    "# pretty charting\n",
    "import seaborn as sns\n",
    "sns.set_palette('muted')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems With Data?\n",
    "Just looking at the dataset, there are a couple of problems:\n",
    "\n",
    "1. Are there missing entries in the data?\n",
    "- Yes there are missing data points within the dataset, just by opening train.csv, you can see that.\n",
    "2. Are there different types of data?\n",
    "- Yes, there is both categorical and numerical data. So we should try to answer how to handle each type of data. There is also binary data, it seems; some fields 0, some are 1. There are no ordinal variables at least.\n",
    "\n",
    "Things to Note/Remember:\n",
    "column['target'] is the vector for which prediction we want. It is equal to 1 for claims suitable for an accelerated approval.\n",
    "column['id'] is the vector for which person it is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### RUN AT BEGINNING AND TRY NOT TO RUN AGAIN - TAKES WAY TOO LONG ####\n",
    "# load in the feature data\n",
    "column = {}\n",
    "list_of_features = []\n",
    "with open('train.csv', 'rb') as file:\n",
    "    reader = csv.reader(file)\n",
    "    headers = reader.next()\n",
    "    \n",
    "    # get headers\n",
    "    for h in headers:\n",
    "        column[h] = []\n",
    "    \n",
    "    # append data\n",
    "    for row in reader:\n",
    "        # just create a matrix of all features\n",
    "        list_of_features.append(row)\n",
    "        \n",
    "        for h, v in zip(headers, row):\n",
    "            # create a dict to access specific columns\n",
    "            column[h].append(v)\n",
    "            \n",
    "# conver to a numpy matrix\n",
    "list_of_features = np.array(list_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "['v18', 'v19', 'v12', 'v13', 'v10', 'v11', 'v16', 'v17', 'v14', 'v15', 'v118', 'v119', 'v114', 'v115', 'v116', 'v117', 'v110', 'v111', 'v112', 'v113', 'v89', 'v88', 'v85', 'v84', 'v87', 'v86', 'v81', 'v80', 'v83', 'v82', 'v69', 'v68', 'v67', 'v66', 'v65', 'v64', 'v63', 'v62', 'v61', 'v60', 'v92', 'v93', 'v90', 'v91', 'v96', 'v97', 'v94', 'v95', 'v107', 'v106', 'v98', 'v99', 'v103', 'v102', 'v101', 'v100', 'v105', 'v104', 'v78', 'v79', 'v74', 'v75', 'v76', 'v77', 'v70', 'v71', 'v72', 'v73', 'v130', 'v131', 'v125', 'v124', 'v127', 'v126', 'v121', 'v120', 'v123', 'v122', 'v129', 'v128', 'v41', 'v40', 'v43', 'v42', 'v45', 'v44', 'v47', 'v46', 'v49', 'v48', 'v23', 'v22', 'v21', 'v20', 'v27', 'v26', 'v25', 'v24', 'v29', 'v28', 'target', 'v56', 'v57', 'v54', 'v55', 'v52', 'v53', 'v50', 'v51', 'v109', 'v58', 'v59', 'v30', 'v31', 'v32', 'v33', 'v34', 'v35', 'v36', 'v37', 'v38', 'v39', 'v108', 'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'ID']\n",
      "114321\n",
      "(114321, 133)\n"
     ]
    }
   ],
   "source": [
    "# how many variables do we have?\n",
    "print len(column.keys())\n",
    "print column.keys()\n",
    "print len(column['v18'])\n",
    "\n",
    "print list_of_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation\n",
    "Need to fill in data with imputed values because there are too many problems.\n",
    "\n",
    "1. What package can we use?\n",
    "2. What imputation method should we use?\n",
    "\n",
    "Answers:\n",
    "1. http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html\n",
    "2. replace with mean for now... but need better method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114321, 129)\n",
      "129\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-ce515f9a3e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mmax_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mnew_col\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mnew_list_of_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "####################### NORMALIZE DATA AND SAVE #######################\n",
    "# write new list_of_features to new txt file\n",
    "csvfile = \"data_normalized/data_numerical_normalized.txt\"\n",
    "\n",
    "numcols = list_of_features.shape[1]\n",
    "numrows = list_of_features.shape[0]\n",
    "\n",
    "new_list_of_features = []\n",
    "categorical_cols = []\n",
    "numerical_cols = []\n",
    "\n",
    "# extract data that is only numerical\n",
    "for i in range(0, numcols):\n",
    "    col = list_of_features[:,i]\n",
    "    \n",
    "    try:\n",
    "        float(col[0])\n",
    "        new_list_of_features.append(col.T)\n",
    "        numerical_cols.append(i)\n",
    "    except:\n",
    "        # do nothing\n",
    "        categorical_cols.append(i)\n",
    "\n",
    "# convert to np matrix\n",
    "new_list_of_features = np.array(new_list_of_features).T\n",
    "print new_list_of_features.shape\n",
    "print new_list_of_features.shape[1]\n",
    "\n",
    "## Normalize\n",
    "for i in range(0, new_list_of_features.shape[1]):\n",
    "    col = new_list_of_features[:,i]\n",
    "    new_col = []\n",
    "    for j in col:\n",
    "        try:\n",
    "            new_col.append(float(j))\n",
    "        except:\n",
    "            new_col.append(j)\n",
    "    \n",
    "    max_col = max(new_col)\n",
    "    (new_col) = np.asarray(new_col)/np.asarray(max_col)\n",
    "    new_list_of_features[:,i] = new_col\n",
    "\n",
    "\n",
    "#Assuming res is a flat list\n",
    "# with open(csvfile, \"w\") as output:\n",
    "#     # write to new file the data\n",
    "#     writer = csv.writer(output, lineterminator='\\n')\n",
    "#     for row in range(0, len(locations)):\n",
    "#         writer.writerow(locations[row,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-19f29fbb6751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "letters = ['a','b','c','d','e','f','g']\n",
    ">>> [ord(x) for x in letters]\n",
    "[97, 98, 99, 100, 101, 102, 103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
